{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e360da8-a7ce-4756-aef9-69fb553dee19",
   "metadata": {},
   "source": [
    "# 0. Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc9e3a7-b3e0-4902-85a5-4d271438957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273185b2-e16f-4dd9-a1bb-a373601f4ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeba4fe-19f2-44c7-a2e3-6b51ddb7dec6",
   "metadata": {},
   "source": [
    "# 1. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2b5188-6df8-4765-a4c9-0b18059d40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd7d809-cc7d-423a-843c-dc4f677bb456",
   "metadata": {},
   "source": [
    "# 2. Mediapipe Open(for gesture data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc5e445-14e9-4a9e-97af-1f4646a54a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collection started.\n",
      "\n",
      "==== Sample 1 waiting to start ====\n",
      "Sample 1 collected. Total frames: 169\n",
      "Sample 1 video saved to 'data\\gsn\\gsn_1.mp4'.\n",
      "Sample 1 data saved to 'data\\gsn\\gsn_1.csv'.\n",
      "Automatically proceeding to the next sample in 0.5 seconds...\n",
      "\n",
      "==== Sample 2 waiting to start ====\n",
      "Sample 2 collected. Total frames: 153\n",
      "Sample 2 video saved to 'data\\gsn\\gsn_2.mp4'.\n",
      "Sample 2 data saved to 'data\\gsn\\gsn_2.csv'.\n",
      "Automatically proceeding to the next sample in 0.5 seconds...\n",
      "\n",
      "==== Sample 3 waiting to start ====\n",
      "Sample 3 collected. Total frames: 4\n",
      "Sample 3 video saved to 'data\\gsn\\gsn_3.mp4'.\n",
      "Sample 3 data saved to 'data\\gsn\\gsn_3.csv'.\n",
      "Automatically proceeding to the next sample in 0.5 seconds...\n",
      "\n",
      "==== Sample 4 waiting to start ====\n",
      "Sample 4 collected. Total frames: 4\n",
      "Sample 4 video saved to 'data\\gsn\\gsn_4.mp4'.\n",
      "Sample 4 data saved to 'data\\gsn\\gsn_4.csv'.\n",
      "Automatically proceeding to the next sample in 0.5 seconds...\n",
      "\n",
      "==== Sample 5 waiting to start ====\n",
      "Sample 5 video saved to 'data\\gsn\\gsn_5.mp4'.\n",
      "Exiting.\n"
     ]
    }
   ],
   "source": [
    "# 폴더 셋업\n",
    "output_dir = r\"data\\아프다\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 이름 설정\n",
    "gesture_name = \"아프다\"\n",
    "\n",
    "# 미디어파이프 설정\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 웹캠 오픈\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "exit_requested = False\n",
    "print(\"Data collection started.\")\n",
    "\n",
    "sample_counter = 0\n",
    "\n",
    "while sample_counter < 100 and not exit_requested:\n",
    "    print(f\"\\n==== Sample {sample_counter+1} waiting to start ====\")\n",
    "    sample_data = []        # 손 랜드마크 데이터를 저장할 리스트\n",
    "    sample_started = False  # 샘플 수집 시작 여부\n",
    "    lost_frames = 0         # 연속적으로 손이 감지되지 않는 프레임 수\n",
    "\n",
    "    # 저장할 파일명 설정\n",
    "    existing_files = [f for f in os.listdir(output_dir) if f.startswith(gesture_name)]\n",
    "    file_number = len(existing_files) // 2 + 1  # 기존 파일 개수를 기준으로 넘버링\n",
    "    csv_filename = os.path.join(output_dir, f\"{gesture_name}_{file_number}.csv\")\n",
    "    video_filename = os.path.join(output_dir, f\"{gesture_name}_{file_number}.mp4\")\n",
    "\n",
    "    # 비디오 저장 설정\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = 30\n",
    "    video_out = cv2.VideoWriter(video_filename, fourcc, fps, (640, 480))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not retrieve frame.\")\n",
    "            exit_requested = True\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        video_out.write(frame)  # 비디오 저장\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image_rgb)\n",
    "\n",
    "        if not sample_started:\n",
    "            cv2.putText(frame, f\"Sample {sample_counter+1}: Place your hand in view\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, f\"Sample {sample_counter+1} collecting...\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        if not sample_started:\n",
    "            if results.multi_hand_landmarks:\n",
    "                sample_started = True\n",
    "                lost_frames = 0  # 손을 감지하면 초기화\n",
    "                frame_data = []\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    landmarks = []\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        landmarks.extend([lm.x, lm.y, lm.z])\n",
    "                    frame_data.append(landmarks)\n",
    "                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                sample_data.append(frame_data)\n",
    "        else:\n",
    "            if results.multi_hand_landmarks:\n",
    "                lost_frames = 0\n",
    "                frame_data = []\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    landmarks = []\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        landmarks.extend([lm.x, lm.y, lm.z])\n",
    "                    frame_data.append(landmarks)\n",
    "                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                sample_data.append(frame_data)\n",
    "            else:\n",
    "                lost_frames += 1\n",
    "                if lost_frames >= 5:\n",
    "                    print(f\"Sample {sample_counter+1} collected. Total frames: {len(sample_data)}\")\n",
    "                    break\n",
    "\n",
    "        cv2.imshow(\"Mediapipe Hands Data Collection\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            exit_requested = True\n",
    "            break\n",
    "\n",
    "    video_out.release()  # 비디오 저장 완료\n",
    "    print(f\"Sample {sample_counter+1} video saved to '{video_filename}'.\")\n",
    "\n",
    "    if exit_requested:\n",
    "        break\n",
    "\n",
    "    # CSV 파일 저장\n",
    "    with open(csv_filename, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # CSV 헤더 작성\n",
    "        header = []\n",
    "        for hand in ['hand1', 'hand2']:\n",
    "            for i in range(21):\n",
    "                header.extend([f\"{hand}_landmark{i}_x\", f\"{hand}_landmark{i}_y\", f\"{hand}_landmark{i}_z\"])\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for frame_data in sample_data:\n",
    "            if len(frame_data) == 0:\n",
    "                row = [0] * 126\n",
    "            elif len(frame_data) == 1:\n",
    "                row = frame_data[0] + ([0] * 63)\n",
    "            else:\n",
    "                row = frame_data[0] + frame_data[1]\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Sample {sample_counter+1} data saved to '{csv_filename}'.\")\n",
    "    sample_counter += 1\n",
    "\n",
    "    # 다음 샘플 대기 시간\n",
    "    print(\"Automatically proceeding to the next sample in 0.5 seconds...\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# 종료 처리\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "hands.close()\n",
    "\n",
    "print(\"Exiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87d17b-4c1e-4c83-92e3-efd9186f9ada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf218_keras37",
   "language": "python",
   "name": "tf218_keras37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
